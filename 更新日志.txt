v1.09版本：

问题一.
实际上，在对话题发起者以及回应者的判断上，
这个模型还存在相当的问题，
模型的判断依据太少，依赖太少，
可能会出现相当多的对应关系误判影响效果，
例如QQ中的@符号显然带有很明确的对象指向性，
由于部分用户习惯将一整段信息拆解为很多小句子，
所以理论上这部分小句子也应该被视为对上述同一话题的一个回应

​​增强消息分组逻辑​​：识别连续小消息并关联到同一话题
​​强化@符号处理​​：显式标记消息指向性
​​改进响应匹配算法​​：结合消息组和@符号进行精准匹配
已修复


问题二.
改进模型中出现了处理2000条信息和19500条信息出现了效率指数级上升的问题，显然时core模块中的双重循环
以及低效的切片操作导致的（切片操作用于判断语句块，也就是更加准确地判断对话和对话者）

准备使用向量化操作和排序搜索解决问题，一次排序和二分法显然效率更高
避免在循环中反复切片DataFrame，而是使用索引和数组操作。
使用更高效的数据结构暂存结果，避免在循环中频繁操作DataFrame。
使用整数索引替代字符串
使用Numba进行JIT编译
使用二分查找优化时间窗口定位
向量化操作替代循环
内存优化
智能进度更新
已修复


问题三.
似乎出现了@消息权重过高的问题。。。考虑降低@权重以避免这一极端项目对整体结果的影响
那么接下来就是建模中遇到的权重分配问题，实际上这是从v1.00版本开始就一直具有的问题（可惜目前仅存有v1.05 v1.06 v1.07 v1.08存档）
我使用的线性拟合模型（甚至连参数都是随便给的）显然不具备体现将关系量化拟合程度足够高的能力，

显然需要考虑使用非线性调整和分层加权，互动频率显然是能体现关系的最重要的指标（考虑到使用的snownlp模型是针对购物网站的情感评价）
所以分三层设计会比较合适一点？（实际上在技术上最好是反复让群聊人员对模型拟合结果进行确认，也就是对模型进行社区化训练，但实际上难以做到）
引入指标重要性自适应调整也许能解决一定的问题（但结果似乎难以预测），考虑引入变异系数(太敷衍了)
引入衰减函数处理显式互动，这是对@消息过分权重的处理手法，理论上作为附加项目处理确实会比较合适
拟合结果显著变好
暂时视为已修复，但实际上仍然是需要优化的部分


问题四.
本模型是相对简单的一对一关系分析模型，显然不具备处理复杂社会关系，尤其是群聊这种很多时候一对多或者多对多聊天的自然语言组合模式
所以从这个角度考虑结合图神经网络计算用户影响力权重，并且通过GNN模型设计处理三跳内社会关系以及影响力权重计算有实际应用上的意义
即使仅通过一个群聊63个用户19000条消息训练出的模型显然不够准确，无法得到合格的检验返回值也是一个巨大的问题。。。
（毕竟本模型可是为了相亲啊！！！！！！）

由于突如其来的电脑储存和python环境问题此问题搁置，留待后续解决


v1.010版本：
我已经忘了这个版本更新了什么内容了。。。因为遭遇的前所未有的环境问题导致我做了非常非常久的docker环境适配，
当想起来要写日志的时候已经是v1.011版本docker容器版本了


v1.011版本（处理完成环境问题）：
实际上本版本完成的更新内容可能相当于之前所有改动幅度的一半以上，但是最大的更新就是完成了适配，
在程序功能以及模型拟合程度上的更新留到v1.012吧，预计引入GNN模型以使模型的拟合效果提升

v1.012版本（关键机器学习模型引入）：


